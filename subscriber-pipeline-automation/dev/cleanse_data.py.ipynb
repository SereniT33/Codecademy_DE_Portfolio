{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff8b306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unit testing\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83181a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename = './dev/cademycode_cleansed_db.log',\n",
    "                    filemode = 'w',\n",
    "                    level = logging.DEBUG,\n",
    "                    force = True)\n",
    "logger.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0f3179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanse_students_table(df):\n",
    "    \"\"\"\n",
    "    Cleanse 'cademycode_students' table following the writeup\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): 'cademycode_students' table from 'cademycode.db'\n",
    "    \n",
    "    Returns:\n",
    "        df (DataFrame): cleansed version of the input table\n",
    "    \"\"\"\n",
    "    df['dob'] = pd.to_datetime(df['dob'])\n",
    "    df['age'] = (pd.to_datetime('now') - df['dob']).astype('<m8[Y]').astype(int)\n",
    "    \n",
    "    df['contact_info'] = df['contact_info'].apply(lambda x: ast.literal_eval(x))\n",
    "    explode_contact_info = pd.json_normalize(df['contact_info'])\n",
    "    df = pd.concat([df.drop('contact_info', axis=1), explode_contact_info], axis=1)\n",
    "    \n",
    "    df['job_id'] = df['job_id'].astype(float)\n",
    "    df['num_course_taken'] = df['num_course_taken'].astype(float)\n",
    "    df['current_career_path_id'] = df['current_career_path_id'].astype(float)\n",
    "    df['time_spent_hrs'] = df['time_spent_hrs'].astype(float)\n",
    "    \n",
    "    df = df.dropna(subset=['job_id'])\n",
    "    df = df.dropna(subset=['num_course_taken'])\n",
    "    \n",
    "    df['current_career_path_id'] = np.where(df['current_career_path_id'].isnull(), 0, df['current_career_path_id'])\n",
    "    df['time_spent_hrs'] = np.where(df['time_spent_hrs'].isnull(), 0, df['time_spent_hrs'])\n",
    "    \n",
    "    df['job_id'] = df['job_id'].astype(int)\n",
    "    df['current_career_path_id'] = df['current_career_path_id'].astype(int)\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedf4628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanse_courses_table(df):\n",
    "    \"\"\"\n",
    "    Cleanse the 'cademycode_courses' table following the writeup\n",
    "        \n",
    "    Parameters:\n",
    "        df (DataFrame): 'cademycode_courses' table from 'cademycode.db'\n",
    "        \n",
    "    Return:\n",
    "        df (DataFrame): cleansed version of the input table\n",
    "    \"\"\"\n",
    "    not_applicable = {'career_path_id': 0,\n",
    "                'career_path_name': 'not applicable',\n",
    "                'hours_to_complete': 0}\n",
    "    df.loc[len(courses)] = not_applicable\n",
    "        \n",
    "     return(df.drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29b16df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanse_student_jobs_table(df):\n",
    "    \"\"\"\n",
    "    Cleanse the 'cademycode_student_jobs' table following the writeup\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): 'cademycode_student_jobs' table from 'cademycode.db'\n",
    "    \n",
    "    Return:\n",
    "        df (DataFrame): cleansed version of the input table\n",
    "    \"\"\"\n",
    "    return(df.drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf21348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_join_students_courses(students, courses):\n",
    "    \"\"\"\n",
    "    Unit test to check if join keys exist between 'cademycode_students' and 'cademy_courses' tables\n",
    "    \n",
    "    Parameters:\n",
    "        students (DataFrame): 'cademycode_students' table from 'cademycode.db'\n",
    "        courses (DataFrame): 'cademycode_courses' table from 'cademycode.db'\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    students_joinkey = students.current_career_path_id.unique()\n",
    "    courses_joinkey = courses.career_path_id.unique()\n",
    "    subset_joinkey = np.isin(students_joinkey, courses_joinkey)\n",
    "    missing_joinkey = students_joinkey[~subset_joinkey]\n",
    "    try:\n",
    "        assert len(missing_joinkey) == 0, \"Missing join key(s):\" + str(list(missing_joinkey)) + \" in 'courses' table\"\n",
    "    except AssertionError as AE:\n",
    "        logger.exception(AE)\n",
    "        raise AE\n",
    "    else:\n",
    "        print('All join keys are present.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8855107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_join_students_jobs(students, student_jobs):\n",
    "    \"\"\"\n",
    "    Unit test to check if join keys exist between 'cademycode_students' and 'cademy_student_jobs' tables\n",
    "    \n",
    "    Parameters:\n",
    "        students (DataFrame): 'cademycode_students' table from 'cademycode.db'\n",
    "        student_jobs (DataFrame): 'cademycode_student_jobs' table from 'cademycode.db'\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    students_joinkey = students.job_id.unique()\n",
    "    jobs_joinkey = student_jobs.job_id.unique()\n",
    "    subset_joinkey = np.isin(students_joinkey, jobs_joinkey)\n",
    "    missing_joinkey = students_joinkey[~subset_joinkey]\n",
    "    try:\n",
    "        assert len(missing_joinkey) == 0, \"Missing join key(s):\" + str(list(missing_joinkey)) + \" in 'student_jobs' table\"\n",
    "    except AssertionError as AE:\n",
    "        logger.exception(AE)\n",
    "        raise AE\n",
    "    else:\n",
    "        print('All join keys are present.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15c8ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_schema_num_cols(local_df, db_df):\n",
    "    \"\"\"\n",
    "    Unit test to check if the number of columns in the cleaned local DataFrame match that of the database table.\n",
    "    \n",
    "    Parameters:\n",
    "        local_df (DataFrame): DataFrame of the cleaned table \n",
    "        db_df (DataFrame): 'cademycode_aggregated' table from 'cademycode_cleansed.db'\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        assert len(local_df.columns) == len(db_df.columns)\n",
    "    except AssertationError as AE:\n",
    "        logger.exception(AE)\n",
    "        raise AE\n",
    "    else:\n",
    "        print('Number of columns in the local DataFrame and the database DataFrame are the same.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94391699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_schema_dtypes(local_df, db_df):\n",
    "    \"\"\"\n",
    "    Unit test to check if column dtypes in the cleaned local DataFrame match the column dtype in the database table.\n",
    "    \n",
    "    Parameters:\n",
    "        local_df (DataFrame): DataFrame of the cleaned table \n",
    "        db_df (DataFrame): 'cademycode_aggregated' table from 'cademycode_cleansed.db'\n",
    "    \n",
    "    Returns:\n",
    "        None  \n",
    "    \"\"\"\n",
    "    name_errors = 0\n",
    "    for col in db_df:\n",
    "        try:\n",
    "            if local_df[col].dtypes != db_df[col].dtypes:\n",
    "                name_errors+=1\n",
    "        except NameError as NE:\n",
    "            logger.exception(NE)\n",
    "            raise NE\n",
    "    \n",
    "    if name_errors > 0:\n",
    "        error_msg = str(name_errors) + \"column dtypes do not match.\"\n",
    "        logger.exception(error_msg)\n",
    "    assert errors == 0, error_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59124912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_nulls(df):\n",
    "    \"\"\"\n",
    "    Unit test to ensure that the cleaned table does not having missing values.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): DataFrame of the cleaned table\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    df_nulls = df[df.isnull().any(axis=1)]\n",
    "    num_nulls = len(df_nulls)\n",
    "    \n",
    "    try:\n",
    "        assert num_nulls == 0, \"There are \" + str(num_nulls) + \" nulls in the table.\"\n",
    "    except AssertionError as AE:\n",
    "        logger.exception(AE)\n",
    "        raise AE\n",
    "    else:\n",
    "        print('No nulls are observed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2ac377",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    # Initialize log\n",
    "    logger.info(\"Start Log\")\n",
    "    \n",
    "    # Check for current version number and calculate next version for changelog\n",
    "    with open(./dev/changelog.md) as f:\n",
    "        lines = f.readlines()\n",
    "    next_ver = int(lines[0].split('.')[2][0])+1\n",
    "    \n",
    "    # Connect to the database and read in the tables\n",
    "    con = sqlite3.connect('./dev/cademycode.db')\n",
    "    students = students = pd.read_sql_query(\"SELECT * FROM cademycode_students\", con)\n",
    "    courses = pd.read_sql_query(\"SELECT * FROM cademycode_courses\", con)\n",
    "    student_jobs = pd.read_sql_query(\"SELECT * FROM cademycode_student_jobs\", con)\n",
    "    con.close()\n",
    "    \n",
    "    # read in the current production tables, if any\n",
    "    try:\n",
    "        con = sqlite3.connect('./prod/cademycode_cleansed.db')\n",
    "        clean_db = pd.read_sql_query(\"SELECT * FROM cademycode_aggregated\", con)\n",
    "        con.close\n",
    "        \n",
    "        # Filter for new students who don't exist in the cleansed database\n",
    "        new_students = students[~np.isin(students.uuid.unique(), clean_db.uuid.unique())]\n",
    "    except:\n",
    "        new_students = students\n",
    "        clean_db = []\n",
    "    \n",
    "    # run the cleanse_students_table() function on the new students only\n",
    "    clean_new_students = cleanse_students_table(new_students)\n",
    "    \n",
    "    # only if there is new students data, clean the rest of the tables\n",
    "    if len(clean_new_students) > 0:\n",
    "        clean_courses = cleanse_courses_table(courses)\n",
    "        clean_student_jobs = cleanse_student_jobs_table(student_jobs)\n",
    "        \n",
    "        ##### UNIT TESTING: ENSURE ALL JOIN KEYS ARE PRESENT BEFORE JOINING #####\n",
    "        test_join_students_courses(clean_new_students, clean_courses)\n",
    "        test_join_students_jobs(clean_new_students, clean_student_jobs)\n",
    "        ##################################################\n",
    "        \n",
    "        # join tables\n",
    "        df_clean = clean_new_students.merge(clean_courses, left_on='current_career_path_id', right_on='career_path_id', how='left')\n",
    "        df_clean= df_clean.merge(clean_student_jobs, on='job_id', how='left')\n",
    "        \n",
    "        ##### UNIT TESTING: ENSURE DATA SCHEMA & COMPLETE DATA #####\n",
    "        if len(clean_db) > 0:\n",
    "            test_schema_num_cols(df_clean, clean_db)\n",
    "            test_schema_dtypes(df_clean, clean_db)\n",
    "        test_nulls(df_clean)\n",
    "        #########################\n",
    "        \n",
    "        # upsert new cleaned data to cademycode_cleansed.db\n",
    "        con = create_engine('sqlite:///./dev/cademycode_cleansed.db', echo=True)\n",
    "        sqlite_connection = con.connect()\n",
    "        df_clean.to_sql('cademycode_aggregated', sqlite_connection, if_exists='append', index=False)\n",
    "        clean_db = pd.read_sql_query(\"SELECT * FROM cademycode_aggregated\", con)\n",
    "        sqlite_connection.close()\n",
    "        \n",
    "        # write new cleaned data to a csv file\n",
    "        clean_db.to_csv('./dev/cademycode_cleansed.csv')\n",
    "        \n",
    "        # create a new automatic changelog entry\n",
    "        new_lines = [\n",
    "              new_lines = [\n",
    "            '## 0.0.' + str(next_ver) + '\\n' +\n",
    "            '### Added\\n' +\n",
    "            '- ' + str(len(df_clean)) + ' more data to database of raw data\\n' \n",
    "        ]\n",
    "        w_lines = ''.join(new_lines + lines)\n",
    "        \n",
    "        # update the changelog\n",
    "         with open('./dev/codecademy_automate_pipeline/changelog.md', 'w') as f:\n",
    "            for line in w_lines:\n",
    "                f.write(line)\n",
    "    else:\n",
    "        print(\"No new data\")\n",
    "        logger.info(\"No new data\")\n",
    "    logger.info(\"End Log\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
